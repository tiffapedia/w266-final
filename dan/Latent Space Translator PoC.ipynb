{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing import text\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, LSTM, Dense, Bidirectional, BatchNormalization, Dropout, Reshape\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6 18 22 26 32 = 2\n",
      "5 9 13 15 23 35 = 1\n",
      "13 17 25 25 29 43 = 1\n",
      "3 23 37 43 49 49 = 1\n",
      "6 6 20 36 40 44 = 2\n",
      "3 7 11 33 41 41 = 1\n",
      "11 19 19 21 27 31 = 1\n",
      "8 18 22 26 40 46 = 2\n",
      "2 6 10 18 34 46 = 2\n",
      "9 11 13 31 35 49 = 1\n"
     ]
    }
   ],
   "source": [
    "# Generate a dataset of strings comprising either odd or even integers, and their corresponding integer labels (1 or 2)\n",
    "\n",
    "def generate_numstring(seed):\n",
    "    numbers = [random.randrange(seed, 50, 2) for x in range(6)]\n",
    "    numbers.sort()\n",
    "    return \" \".join([str(x) for x in numbers])\n",
    "\n",
    "def build_dataset(n_samples):\n",
    "    n_samples = n_samples/2\n",
    "    evens_list = [generate_numstring(0) for x in range(n_samples)]\n",
    "    evens_labels = [2 for x in range(n_samples)]\n",
    "    odds_list = [generate_numstring(1) for x in range(n_samples)]\n",
    "    odds_labels = [1 for x in range(n_samples)]\n",
    "    strings_pre = evens_list + odds_list\n",
    "    labels_pre = evens_labels + odds_labels\n",
    "    merge = list(zip(strings_pre, labels_pre))\n",
    "    random.shuffle(merge)\n",
    "    strings, labels = zip(*merge)\n",
    "    return(strings, labels)\n",
    "\n",
    "data = build_dataset(100000)\n",
    "X = data[0]\n",
    "X2 = [\"|\"+x[:-1] for x in X]\n",
    "y = data[1]\n",
    "\n",
    "for row in range(10):\n",
    "    print(\"{} = {}\".format(X[row], y[row]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple character-level LSTM and verify accuracy\n",
    "\n",
    "# Set Parameters\n",
    "x_length = 18\n",
    "training_ratio = .75\n",
    "training_size = int(len(X)*training_ratio)\n",
    "num_classes = 3\n",
    "num_unique_symbols = 14\n",
    "H = 252\n",
    "epochs = 100\n",
    "optimizer = 'rmsprop'\n",
    "batch_size = 64\n",
    "learning_rate = .0001\n",
    "\n",
    "# Encode strings\n",
    "t = text.Tokenizer(\n",
    "    char_level=True,\n",
    "    filters=None,\n",
    "    lower=True,\n",
    "    num_words=num_unique_symbols,\n",
    "    oov_token='unk'\n",
    ")\n",
    "\n",
    "# Convert strings to sequences, pad them to uniform length, and divide up training and test sets\n",
    "t.fit_on_texts(X2)\n",
    "index_word = {v: k for k, v in t.word_index.items()}\n",
    "X_seq = t.texts_to_sequences(X)\n",
    "X2_seq = t.texts_to_sequences(X2)\n",
    "X_padded = sequence.pad_sequences(X_seq, maxlen=x_length)\n",
    "X2_padded = sequence.pad_sequences(X2_seq, maxlen=x_length)\n",
    "X_train = X_padded[:training_size]\n",
    "X2_train = X2_padded[:training_size]\n",
    "X_test = X_padded[training_size:]\n",
    "X2_test = X2_padded[training_size:]\n",
    "y_train = y[:training_size]\n",
    "y_test = y[training_size:]\n",
    "\n",
    "# One-hot encode everything\n",
    "encoded_X_train = to_categorical(X_train, num_classes=num_unique_symbols)\n",
    "encoded_X2_train = to_categorical(X2_train, num_classes=num_unique_symbols)\n",
    "encoded_X_test = to_categorical(X_test, num_classes=num_unique_symbols)\n",
    "encoded_X2_test = to_categorical(X2_test, num_classes=num_unique_symbols)\n",
    "encoded_y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "encoded_y_test = to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 64)                19712     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 19,907\n",
      "Trainable params: 19,907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/100\n",
      "7500/7500 [==============================] - 4s 493us/step - loss: 0.9909 - acc: 0.5632 - val_loss: 0.8682 - val_acc: 0.5580\n",
      "Epoch 2/100\n",
      "7500/7500 [==============================] - 3s 367us/step - loss: 0.6781 - acc: 0.7096 - val_loss: 0.4942 - val_acc: 0.8992\n",
      "Epoch 3/100\n",
      "7500/7500 [==============================] - 3s 365us/step - loss: 0.2895 - acc: 0.9568 - val_loss: 0.1786 - val_acc: 0.9368\n",
      "Epoch 4/100\n",
      "7500/7500 [==============================] - 3s 369us/step - loss: 0.1394 - acc: 0.9497 - val_loss: 0.1245 - val_acc: 0.9544\n",
      "Epoch 5/100\n",
      "7500/7500 [==============================] - 3s 370us/step - loss: 0.1144 - acc: 0.9563 - val_loss: 0.1041 - val_acc: 0.9616\n",
      "Epoch 6/100\n",
      "7500/7500 [==============================] - 3s 372us/step - loss: 0.0975 - acc: 0.9633 - val_loss: 0.0928 - val_acc: 0.9632\n",
      "Epoch 7/100\n",
      "7500/7500 [==============================] - 3s 369us/step - loss: 0.0878 - acc: 0.9656 - val_loss: 0.0859 - val_acc: 0.9660\n",
      "Epoch 8/100\n",
      "7500/7500 [==============================] - 3s 368us/step - loss: 0.0796 - acc: 0.9701 - val_loss: 0.0814 - val_acc: 0.9668\n",
      "Epoch 9/100\n",
      "7500/7500 [==============================] - 3s 370us/step - loss: 0.0746 - acc: 0.9703 - val_loss: 0.0874 - val_acc: 0.9660\n",
      "Epoch 10/100\n",
      "7500/7500 [==============================] - 3s 366us/step - loss: 0.0711 - acc: 0.9704 - val_loss: 0.0870 - val_acc: 0.9668\n",
      "Accuracy: 96.68%\n"
     ]
    }
   ],
   "source": [
    "# A simple LSTM model to classify whether a string is even or odd\n",
    "opt = optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(H, input_shape=(x_length, num_unique_symbols)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2)]\n",
    "model.fit(encoded_X_train, encoded_y_train, epochs=epochs, callbacks=callbacks, batch_size=batch_size,\n",
    "          validation_data=(encoded_X_test, encoded_y_test))\n",
    "scores = model.evaluate(encoded_X_test, encoded_y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define Parameters for this model\n",
    "num_unique_symbols = 14\n",
    "x_length = 18\n",
    "H = 256\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "learning_rate = .0001\n",
    "\n",
    "# define training encoder\n",
    "encoder_inputs = Input(shape=(x_length, num_unique_symbols))\n",
    "encoder = LSTM(H, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_dense = Dense(num_classes, activation='softmax', name=\"encoder_final\")\n",
    "encoder_outputs = encoder_dense(encoder_outputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# define training decoder\n",
    "decoder_inputs = Input(shape=(None, num_unique_symbols))\n",
    "decoder_lstm = LSTM(H, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_unique_symbols, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Combine training inputs into a single training model\n",
    "model = Model([encoder_inputs, decoder_inputs], [encoder_outputs, decoder_outputs])\n",
    "\n",
    "# define inference encoder\n",
    "encoder_model = Model(encoder_inputs, [encoder_outputs] + encoder_states)\n",
    "\n",
    "# define inference decoder\n",
    "decoder_state_input_h = Input(shape=(H,))\n",
    "decoder_state_input_c = Input(shape=(H,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "75000/75000 [==============================] - 324s 4ms/step - loss: 1.2619 - encoder_final_loss: 0.0712 - dense_9_loss: 1.1907 - encoder_final_acc: 0.9822 - dense_9_acc: 0.5857\n",
      "Epoch 2/20\n",
      "75000/75000 [==============================] - 309s 4ms/step - loss: 0.5111 - encoder_final_loss: 0.0012 - dense_9_loss: 0.5099 - encoder_final_acc: 0.9998 - dense_9_acc: 0.8058\n",
      "Epoch 3/20\n",
      "75000/75000 [==============================] - 308s 4ms/step - loss: 0.3414 - encoder_final_loss: 7.8879e-04 - dense_9_loss: 0.3406 - encoder_final_acc: 0.9998 - dense_9_acc: 0.8770\n",
      "Epoch 4/20\n",
      "75000/75000 [==============================] - 309s 4ms/step - loss: 0.2153 - encoder_final_loss: 6.1652e-04 - dense_9_loss: 0.2147 - encoder_final_acc: 0.9998 - dense_9_acc: 0.9316\n",
      "Epoch 5/20\n",
      "75000/75000 [==============================] - 310s 4ms/step - loss: 0.1324 - encoder_final_loss: 5.4078e-04 - dense_9_loss: 0.1319 - encoder_final_acc: 0.9998 - dense_9_acc: 0.9650\n",
      "Epoch 6/20\n",
      "75000/75000 [==============================] - 309s 4ms/step - loss: 0.0839 - encoder_final_loss: 5.5898e-04 - dense_9_loss: 0.0833 - encoder_final_acc: 0.9998 - dense_9_acc: 0.9811\n",
      "Epoch 7/20\n",
      "75000/75000 [==============================] - 309s 4ms/step - loss: 0.0573 - encoder_final_loss: 4.3299e-04 - dense_9_loss: 0.0569 - encoder_final_acc: 0.9999 - dense_9_acc: 0.9882\n",
      "Epoch 8/20\n",
      "17216/75000 [=====>........................] - ETA: 3:57 - loss: 0.0445 - encoder_final_loss: 6.0626e-04 - dense_9_loss: 0.0439 - encoder_final_acc: 0.9998 - dense_9_acc: 0.9918"
     ]
    }
   ],
   "source": [
    "# Compile and train the model\n",
    "opt = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.fit([encoded_X_train, encoded_X2_train], [encoded_y_train, encoded_X_train], epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def predict_sequence(infenc, infdec, source, n_steps, cardinality, translate=False):\n",
    "    '''\n",
    "    Given a source array, feed it through the autoencoder to predict a string - either itself in the naive case \n",
    "    where translation is turned off, or run gradient ascent to convert the source array to a target category,\n",
    "    and run that through the autoencoder to get the translated version.\n",
    "    '''\n",
    "    source_string = one_hot_decode(index_word, source[0])\n",
    "    # feed the source into the encoder inference model\n",
    "    encode = infenc.predict(source)\n",
    "    # make prediction of category for source sequence\n",
    "    label_prediction_probs = encode[0][0]\n",
    "    label_prediction = np.argmax(label_prediction_probs)\n",
    "    source_label_prediction = \"odd\" if label_prediction == 1 else \"even\"\n",
    "    source_label_certainty = label_prediction_probs[label_prediction]\n",
    "    # start of sequence input\n",
    "    target_seq = np.array([0.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\n",
    "    \n",
    "    # If set to translate, run gradient ascent to maximize to the target_label\n",
    "    if translate:\n",
    "        target_label = 1 if label_prediction==2 else 2\n",
    "        new_source = translate_sequence(source, infenc, target_label)\n",
    "        encode = infenc.predict(new_source)\n",
    "    \n",
    "    # feed the state into the decoder to make a prediction of the string\n",
    "    state = encode[1:]\n",
    "    output = list()\n",
    "    for t in range(n_steps):\n",
    "        # predict next char\n",
    "        yhat, h, c = infdec.predict([target_seq] + state)\n",
    "        # store prediction\n",
    "        output.append(yhat[0,0,:])\n",
    "        # update state\n",
    "        state = [h, c]\n",
    "        # update target sequence\n",
    "        target_seq = yhat\n",
    "    predicted_sequence = np.array([output])\n",
    "    # Convert the response back to a string\n",
    "    decode_string = one_hot_decode(index_word, predicted_sequence[0])\n",
    "    \n",
    "    # make prediction of category for predicted response\n",
    "    decode_prediction = infenc.predict(predicted_sequence)\n",
    "    label_prediction_probs = decode_prediction[0][0]\n",
    "    label_prediction = np.argmax(label_prediction_probs)\n",
    "    decode_label_prediction = \"odd\" if label_prediction == 1 else \"even\"\n",
    "    decode_label_certainty = label_prediction_probs[label_prediction]\n",
    "    \n",
    "    return (source_string, source_label_prediction, source_label_certainty,\n",
    "            decode_string, decode_label_prediction, decode_label_certainty)\n",
    "\n",
    "def score_similarity(s1, s2):\n",
    "    '''\n",
    "    Measure the similarity of two strings character-by-character.  Not a very effective way of scoring this.\n",
    "    '''\n",
    "    list_s1 = list(s1)\n",
    "    list_s2 = list(s2)\n",
    "    score = 0\n",
    "    increment = 100/len(s1)\n",
    "    for char in range(len(list_s1)):\n",
    "        if char == len(list_s1) or char == len(list_s2):\n",
    "            break\n",
    "        elif list_s1[char] == list_s2[char]:\n",
    "            score += increment\n",
    "    return score\n",
    "\n",
    "def one_hot_decode(reverse_dict, encoded_seq):\n",
    "    '''\n",
    "    Turn a one-hot encoded array back into a readable string.\n",
    "    '''\n",
    "    retn = []\n",
    "    seq = [np.argmax(vector) for vector in encoded_seq]\n",
    "    for s in seq:\n",
    "        if s > 0:\n",
    "            retn.append(reverse_dict[s])\n",
    "    return \"\".join(retn)\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())\n",
    "    #return x / K.max(x)\n",
    "\n",
    "def translate_sequence(seq, model, target):\n",
    "    '''\n",
    "    Run gradient ascent to maximize a sequence to a target category\n",
    "    '''\n",
    "    target_probability = .95 # You want the model to be this certain the string is in the target category\n",
    "    input_txt = model.input\n",
    "    loss = K.mean(model.output[0][:, target])\n",
    "    grads = K.gradients(loss, input_txt)[0]\n",
    "    grads = normalize(grads)\n",
    "    iterate = K.function([input_txt], [loss, grads])\n",
    "    \n",
    "    output_sequence = seq.copy()\n",
    "    for i in range(20):\n",
    "        loss_value, grads_value = iterate([output_sequence])\n",
    "        output_sequence += grads_value\n",
    "        \n",
    "        probs = model.predict(output_sequence)[0][0]\n",
    "        cat = np.argmax(probs)\n",
    "        top_prob = probs[cat]\n",
    "        if loss_value <= 0. or (cat==target and top_prob > target_probability):\n",
    "            break\n",
    "    return output_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Source Prediction</th>\n",
       "      <th>Source Certainty</th>\n",
       "      <th>Decoded</th>\n",
       "      <th>Decoded Prediction</th>\n",
       "      <th>Decoded Certainty</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 4 8 12 36 44</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0 4 8 12 32 44</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 7 15 15 21 29</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1 5 15 15 25 29</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6 10 12 14 40 48</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0 10 16 14 42 48</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 8 16 28 32 40</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>2 8 18 28 30 40</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 6 24 30 40 40</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>4 6 20 30 40 40</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9 19 21 23 35 49</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>9 19 21 23 35 45</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2 2 16 38 38 42</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>2 2 18 38 38 42</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3 9 23 23 37 49</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>3 9 23 29 39 47</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5 9 15 23 41 43</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5 9 25 31 41 43</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5 23 29 33 35 49</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>5 23 29 39 39 45</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Source Source Prediction  Source Certainty           Decoded  \\\n",
       "0    0 4 8 12 36 44              even          0.999992    0 4 8 12 32 44   \n",
       "1   1 7 15 15 21 29               odd          0.999995   1 5 15 15 25 29   \n",
       "2  6 10 12 14 40 48              even          0.999973  0 10 16 14 42 48   \n",
       "3   2 8 16 28 32 40              even          0.999987   2 8 18 28 30 40   \n",
       "4   4 6 24 30 40 40              even          0.999992   4 6 20 30 40 40   \n",
       "5  9 19 21 23 35 49               odd          0.999994  9 19 21 23 35 45   \n",
       "6   2 2 16 38 38 42              even          0.999869   2 2 18 38 38 42   \n",
       "7   3 9 23 23 37 49               odd          0.999969   3 9 23 29 39 47   \n",
       "8   5 9 15 23 41 43               odd          0.999997   5 9 25 31 41 43   \n",
       "9  5 23 29 33 35 49               odd          0.999986  5 23 29 39 39 45   \n",
       "\n",
       "  Decoded Prediction  Decoded Certainty  Similarity  \n",
       "0               even           0.999992          91  \n",
       "1                odd           0.999996          78  \n",
       "2               even           0.999988          78  \n",
       "3               even           0.999990          78  \n",
       "4               even           0.999995          84  \n",
       "5                odd           0.999994          90  \n",
       "6               even           0.999946          84  \n",
       "7                odd           0.999972          72  \n",
       "8                odd           0.999996          72  \n",
       "9                odd           0.999982          78  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_results = {'Source':[], 'Source Prediction':[], 'Source Certainty':[],\n",
    "                   'Decoded':[], 'Decoded Prediction':[], 'Decoded Certainty':[], 'Similarity': []}\n",
    "for _ in range(10):\n",
    "    target = predict_sequence(encoder_model, decoder_model, encoded_X_test[[_]], x_length, num_unique_symbols)\n",
    "    decoder_results['Source'].append(target[0])\n",
    "    decoder_results['Source Prediction'].append(target[1])\n",
    "    decoder_results['Source Certainty'].append(target[2])\n",
    "    decoder_results['Decoded'].append(target[3])\n",
    "    decoder_results['Decoded Prediction'].append(target[4])\n",
    "    decoder_results['Decoded Certainty'].append(target[5])\n",
    "    decoder_results['Similarity'].append(score_similarity(target[0], target[3]))\n",
    "\n",
    "\n",
    "pd.DataFrame.from_dict(decoder_results)[['Source', 'Source Prediction', 'Source Certainty', \n",
    "                                         'Decoded', 'Decoded Prediction', 'Decoded Certainty',\n",
    "                                         'Similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Source Prediction</th>\n",
       "      <th>Source Certainty</th>\n",
       "      <th>Translated</th>\n",
       "      <th>Translated Prediction</th>\n",
       "      <th>Translated Certainty</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 4 8 12 36 44</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>77777739939999 9</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 7 15 15 21 29</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0000044444444888</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6 10 12 14 40 48</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>777739999999999 9</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 8 16 28 32 40</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>777777739999 99 9</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 6 24 30 40 40</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>777737939999999 4</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9 19 21 23 35 49</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>00040 44 48 48888</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2 2 16 38 38 42</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>777777739999 99 4</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3 9 23 23 37 49</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>880 40 40 48 4884</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5 9 15 23 41 43</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>00 0044444444888</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5 23 29 33 35 49</td>\n",
       "      <td>odd</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>00 40 44 48848888</td>\n",
       "      <td>even</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Source Source Prediction  Source Certainty         Translated  \\\n",
       "0    0 4 8 12 36 44              even          0.999992   77777739939999 9   \n",
       "1   1 7 15 15 21 29               odd          0.999995   0000044444444888   \n",
       "2  6 10 12 14 40 48              even          0.999973  777739999999999 9   \n",
       "3   2 8 16 28 32 40              even          0.999987  777777739999 99 9   \n",
       "4   4 6 24 30 40 40              even          0.999992  777737939999999 4   \n",
       "5  9 19 21 23 35 49               odd          0.999994  00040 44 48 48888   \n",
       "6   2 2 16 38 38 42              even          0.999869  777777739999 99 4   \n",
       "7   3 9 23 23 37 49               odd          0.999969  880 40 40 48 4884   \n",
       "8   5 9 15 23 41 43               odd          0.999997   00 0044444444888   \n",
       "9  5 23 29 33 35 49               odd          0.999986  00 40 44 48848888   \n",
       "\n",
       "  Translated Prediction  Translated Certainty  Score  \n",
       "0                   odd              0.999997      7  \n",
       "1                  even              0.999999      0  \n",
       "2                   odd              0.999992      0  \n",
       "3                   odd              0.999995      6  \n",
       "4                   odd              0.999994      6  \n",
       "5                  even              0.999997      0  \n",
       "6                   odd              0.999995     12  \n",
       "7                  even              0.999998     30  \n",
       "8                  even              0.999999      6  \n",
       "9                  even              0.999996      0  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_results = {'Source':[], 'Source Prediction':[], 'Source Certainty':[],\n",
    "                   'Translated':[], 'Translated Prediction':[], 'Translated Certainty':[], 'Score': []}\n",
    "for _ in range(10):\n",
    "    target = predict_sequence(encoder_model, decoder_model, encoded_X_test[[_]], x_length, num_unique_symbols, translate=True)\n",
    "    decoder_results['Source'].append(target[0])\n",
    "    decoder_results['Source Prediction'].append(target[1])\n",
    "    decoder_results['Source Certainty'].append(target[2])\n",
    "    decoder_results['Translated'].append(target[3])\n",
    "    decoder_results['Translated Prediction'].append(target[4])\n",
    "    decoder_results['Translated Certainty'].append(target[5])\n",
    "    decoder_results['Score'].append(score_similarity(target[0], target[3]))\n",
    "\n",
    "pd.DataFrame.from_dict(decoder_results)[['Source', 'Source Prediction', 'Source Certainty', \n",
    "                                         'Translated', 'Translated Prediction', 'Translated Certainty',\n",
    "                                         'Score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_category = 1\n",
    "input_txt = encoder_model.input\n",
    "layer_dict = dict([(layer.name, layer) for layer in encoder_model.layers[1:]])\n",
    "layer_name = 'encoder_final'\n",
    "layer_input = layer_dict[layer_name].input\n",
    "loss = K.mean(encoder_model.output[0][:, target_category])\n",
    "grads = K.gradients(loss, layer_input)[0]\n",
    "grads = normalize(grads)\n",
    "iterate = K.function([input_txt], [loss, grads])\n",
    "step = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,18,14) (1,256) (1,18,14) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-de8ad9bc9ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_sequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutput_sequence\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgrads_value\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#revised_output = manual_prediction(output_sequence, weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,18,14) (1,256) (1,18,14) "
     ]
    }
   ],
   "source": [
    "output_sequence = encoded_X_test[[0]].copy()\n",
    "for i in range(3):\n",
    "    loss_value, grads_value = iterate([output_sequence])\n",
    "    output_sequence += grads_value * step\n",
    "\n",
    "    #revised_output = manual_prediction(output_sequence, weights)\n",
    "    #cat = np.argmax(revised_output)\n",
    "    #top_prob = revised_output[cat]\n",
    "    \n",
    "    #print('Current loss value: {}, predicted category: {}, certainty: {}'\n",
    "    #      .format(loss_value, cat, top_prob))\n",
    "    print(loss_value)\n",
    "    if loss_value <= 0. or (cat==target_category and top_prob > .9):\n",
    "        # some filters get stuck to 0, we can skip them\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_29:0' shape=(?, 18, 14) dtype=float32>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 18, 14)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not sure this is necessary\n",
    "\n",
    "def softmax(raw_preds):\n",
    "    '''\n",
    "    pass raw predictions through softmax activation function\n",
    "    '''\n",
    "    out = np.exp(raw_preds) # exponentiate vector of raw predictions\n",
    "    return out/np.sum(out)\n",
    "\n",
    "def manual_prediction(h, weights):\n",
    "    '''\n",
    "    Take raw model output and manually compute dense layer, softmax and return category prediction\n",
    "    '''\n",
    "    w_out = weights[0]\n",
    "    b_out = weights[1]\n",
    "    logits = np.matmul(h, w_out)+b_out\n",
    "    return softmax(logits)[0]\n",
    "\n",
    "layer_dict = dict([(layer.name, layer) for layer in encoder_model.layers])\n",
    "weights = layer_dict['encoder_final'].get_weights()\n",
    "w_out = weights[0]\n",
    "b_out = weights[1]\n",
    "encode = encoder_model.predict(encoded_X_test[[0]])\n",
    "h = encode[1]\n",
    "logits = np.matmul(h, w_out)+b_out\n",
    "prediction = encode[0]\n",
    "manual_prediction(h, weights, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

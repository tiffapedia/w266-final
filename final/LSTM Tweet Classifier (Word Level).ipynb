{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dolmstead/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# LSTM with Dropout for sequence classification in the IMDB dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing import text\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Input, LSTM, CuDNNLSTM, Dense, Bidirectional, BatchNormalization, Dropout, Reshape, Concatenate, Add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "import time\n",
    "import datetime\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allocator_type ='BFC'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>134968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>134968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>134968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>134968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>134968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>134968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>134968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>134967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>134968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>134968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>134968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text\n",
       "region        \n",
       "3       134968\n",
       "4       134968\n",
       "5       134968\n",
       "7       134968\n",
       "10      134968\n",
       "13      134968\n",
       "14      134968\n",
       "15      134968\n",
       "18      134968\n",
       "19      134967\n",
       "20      134968\n",
       "21      134968\n",
       "22      134968"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/tweets_labelled_balanced.csv')\n",
    "df.dropna(inplace=True)\n",
    "df.region = df.region.astype(int)\n",
    "df['text'] = df['text'].apply(lambda x:x.lower())\n",
    "X = df['text'].tolist()\n",
    "y = df['region'].tolist()\n",
    "df_counts = df.groupby('region').count()\n",
    "top_category_num = max(df_counts['text'])\n",
    "top_category_name = df_counts[df_counts['text']==max(df_counts['text'])].index[0]\n",
    "categories = df_counts.index.tolist()\n",
    "df_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters\n",
    "V = 20000\n",
    "x_length = 50\n",
    "training_ratio = .75\n",
    "training_size = int(len(X)*training_ratio)\n",
    "num_classes = 23\n",
    "embedding_vector_length = 200\n",
    "num_layers = 2\n",
    "H = 200\n",
    "epochs = 100\n",
    "optimizer = 'rmsprop'\n",
    "batch_size = 32\n",
    "learning_rate = .001\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 1315937 examples, test set has 438646 examples\n"
     ]
    }
   ],
   "source": [
    "# Convert text to integer indices, separate test and training sets\n",
    "t = text.Tokenizer(num_words=V, lower=True)\n",
    "t.fit_on_texts(X)\n",
    "X_seq = t.texts_to_sequences(X)\n",
    "word_index = t.word_index\n",
    "index_word = {v: k for k, v in t.word_index.items()}\n",
    "X_pad = sequence.pad_sequences(X_seq, maxlen=x_length)\n",
    "X_train = X_pad[:training_size]\n",
    "X_test = X_pad[training_size:]\n",
    "y_train = y[:training_size]\n",
    "y_test = y[training_size:]\n",
    "one_hot_y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "one_hot_y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "print(\"Training set has {} examples, test set has {} examples\".format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator to feed batches into the model\n",
    "class OneHotBatch(Sequence):\n",
    "  def __init__(self, X_data, y_data, batch_size, V, num_classes):\n",
    "    self.X_data = X_data\n",
    "    self.y_data = y_data\n",
    "    self.batch_size = batch_size\n",
    "    self.V = V\n",
    "    self.num_classes = num_classes\n",
    "\n",
    "  def __len__(self):\n",
    "     return int(np.ceil(len(self.X_data) / float(self.batch_size)))\n",
    "\n",
    "  def __getitem__(self, batch_id):\n",
    "    start = batch_id * self.batch_size\n",
    "    finish = start + self.batch_size\n",
    "    X = self.X_data[start:finish]\n",
    "    y = to_categorical(self.y_data[start:finish], num_classes=self.num_classes)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Load Glove embeddings\n",
    "embeddings_index = {}\n",
    "f = open('data/glove.6B.200d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "embedding_matrix = np.zeros((V, embedding_vector_length))\n",
    "for word, i in word_index.items():\n",
    "    if i == V:\n",
    "        break\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Classifier Model\n",
    "\n",
    "classifier_inputs = Input(shape=(None, ))\n",
    "classifier_embedding = Embedding(V, embedding_vector_length, weights=[embedding_matrix], name=\"classifier_embedding\")\n",
    "model_input = classifier_embedding(classifier_inputs)\n",
    "classifier_lvl1 = Bidirectional(CuDNNLSTM(H, return_sequences=True), name=\"bidirectional_lstm1\")\n",
    "first_level = classifier_lvl1(model_input)\n",
    "classifier_lvl2 = CuDNNLSTM(H, name=\"classifier_lstm2\")\n",
    "classifier_outputs = classifier_lvl2(first_level)\n",
    "classifier_dropout = Dropout(0.2, name=\"classifier_dropout\")\n",
    "classifier_dense = Dense(num_classes, activation='softmax', name=\"classifier_dense\")\n",
    "classifier_outputs = classifier_dropout(classifier_outputs)\n",
    "classifier_outputs = classifier_dense(classifier_outputs)\n",
    "\n",
    "model = Model(classifier_inputs, classifier_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "classifier_embedding (Embedd (None, None, 200)         4000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_lstm1 (Bidirec (None, None, 400)         643200    \n",
      "_________________________________________________________________\n",
      "classifier_lstm2 (CuDNNLSTM) (None, 200)               481600    \n",
      "_________________________________________________________________\n",
      "classifier_dropout (Dropout) (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "classifier_dense (Dense)     (None, 23)                4623      \n",
      "=================================================================\n",
      "Total params: 5,129,423\n",
      "Trainable params: 5,129,423\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "41124/41124 [==============================] - 1977s 48ms/step - loss: 2.3267 - acc: 0.1959 - val_loss: 2.3086 - val_acc: 0.2016\n",
      "Epoch 2/100\n",
      "41124/41124 [==============================] - 1979s 48ms/step - loss: 2.3033 - acc: 0.2086 - val_loss: 2.2998 - val_acc: 0.2112\n",
      "Epoch 3/100\n",
      "41124/41124 [==============================] - 1973s 48ms/step - loss: 2.2973 - acc: 0.2141 - val_loss: 2.3125 - val_acc: 0.2122\n",
      "Epoch 4/100\n",
      "41124/41124 [==============================] - 1974s 48ms/step - loss: 2.2929 - acc: 0.2180 - val_loss: 2.3053 - val_acc: 0.2125\n",
      "Finished in 2:11:45.541172\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "start_time = time.time()\n",
    "\n",
    "# Generators\n",
    "train_generator = OneHotBatch(X_data=X_train, y_data=y_train, batch_size=batch_size, V=V, num_classes=num_classes)\n",
    "validation_generator = OneHotBatch(X_data=X_test, y_data=y_test, batch_size=batch_size, V=V, num_classes=num_classes)\n",
    "\n",
    "# Compile and train the model\n",
    "#opt = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False, clipvalue=.05)\n",
    "opt = optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "callbacks = [EarlyStopping(monitor='val_acc', patience=3, min_delta=.03, restore_best_weights=True),\n",
    "             ModelCheckpoint(filepath='models/Twitter_Classifier_FULL.h5', \n",
    "                             monitor='val_acc', save_best_only=True),\n",
    "             TensorBoard(log_dir='./logs/Twitter_Classifier_FULL', histogram_freq=0, batch_size=32, write_graph=False, \n",
    "                         write_grads=True, write_images=True, embeddings_freq=0, embeddings_layer_names=None, \n",
    "                         embeddings_metadata=None, embeddings_data=None, update_freq='epoch')]\n",
    "\n",
    "model.fit_generator(generator=train_generator, callbacks=callbacks, epochs=100, validation_data=validation_generator)\n",
    "                    #max_queue_size=10, workers=5, use_multiprocessing=True)\n",
    "# Final evaluation of the model\n",
    "end_time = time.time()\n",
    "run_time = datetime.timedelta(seconds=end_time-start_time)\n",
    "print(\"Finished in {}\".format(run_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'Classifier_full_balanced_1Bi1L_rms'\n",
    "#model.save('models/{}.h5'.format(model_name))\n",
    "\n",
    "# Save the model and weights to disk\n",
    "with open('models/Classifier_full_balanced_1Bi1L_20k.json', 'w', encoding='utf8') as f:\n",
    "    f.write(model.to_json())\n",
    "model.save_weights('models/Classifier_full_balanced_1Bi1L_rms_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = [\"if you're looking for work in va, check out this #job: #hiring #careerarc\", \n",
    "          \"i'm at cassell’s burgers in los angeles, ca\"]\n",
    "test_sequence = t.texts_to_sequences(tweets)\n",
    "test_padded = sequence.pad_sequences(test_sequence, maxlen=x_length)\n",
    "test_prediction_probs = model.predict_on_batch(test_padded)\n",
    "np.argmax(test_prediction_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tweets = X[training_size:]\n",
    "\n",
    "Xt = X_test\n",
    "validation_generator = OneHotBatch(X_test, y_test, batch_size=batch_size, V=V, num_classes=num_classes)\n",
    "#Xt_onehot = to_categorical(Xt, num_classes=num_unique_symbols)\n",
    "prediction_probs = model.predict_generator(validation_generator)\n",
    "predictions = np.argmax(prediction_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 4, 5, 7, 10, 13, 14, 15, 18, 19, 20, 21, 22]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_regions = np.unique(predictions).tolist()\n",
    "predicted_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we got the earth in the blunt\n"
     ]
    }
   ],
   "source": [
    "def sequence_to_text(tokenizer, array):\n",
    "    return \" \".join([index_word[x] for x in array if x > 0])\n",
    "\n",
    "print(sequence_to_text(t, X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each predicted region, find the tweet that the model is MOST confident belongs\n",
    "regions = [\"albuquerque\", \"billings\", \"calgary\", \"charlotte\", \"chicago\", \"cincinnati\", \"denver\", \"houston\", \"kansas city\",\n",
    "           \"las vegas\", \"los angeles\", \"minneapolis\", \"montreal\", \"nashville\", \"new york\", \"oklahoma city\", \"phoenix\",\n",
    "           \"pittsburgh\", \"san francisco\", \"seattle\", \"tampa\", \"toronto\", \"washington\"]\n",
    "best_tweets = dict()\n",
    "\n",
    "for region in predicted_regions:\n",
    "    best_tweets[regions[region]] = {'tweet': '', 'prob': 0, 'index': 0}\n",
    "\n",
    "for i in range(len(prediction_probs)):\n",
    "    top_region_int = np.argmax(prediction_probs[i])\n",
    "    top_region = regions[top_region_int]\n",
    "    top_score = prediction_probs[i][top_region_int]\n",
    "    if top_score > best_tweets[top_region]['prob']:\n",
    "        best_tweets[top_region]['prob'] = top_score\n",
    "        best_tweets[top_region]['tweet'] = sequence_to_text(t, Xt[i])\n",
    "        best_tweets[top_region]['index'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>prob</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>albuquerque</th>\n",
       "      <td>72883</td>\n",
       "      <td>0.155828</td>\n",
       "      <td>ulta beauty is hiring our newest professional in carsoncity nv we would love to connect with you if interested click here to learn more beauty advisor seasonal hiring ultabeauty cosmetology job jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charlotte</th>\n",
       "      <td>154751</td>\n",
       "      <td>0.997735</td>\n",
       "      <td>your talent drives your legacy at construction apply today conway sc hiring construction construction charleston sc job jobs careerarc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chicago</th>\n",
       "      <td>337882</td>\n",
       "      <td>0.99812</td>\n",
       "      <td>can you recommend anyone for this job software support engineer engineering chicago il veterans hiring careerarc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cincinnati</th>\n",
       "      <td>252895</td>\n",
       "      <td>0.997226</td>\n",
       "      <td>connect with us to help change the world if you’re ready to make an impact we’d love to hear from you please submit your for our newest open role in cincinnati oh site controller cincinnati oh fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>houston</th>\n",
       "      <td>159792</td>\n",
       "      <td>0.994945</td>\n",
       "      <td>want to work at performance food group we're hiring in shreveport la click for details driver cdl transportation job jobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>los angeles</th>\n",
       "      <td>204404</td>\n",
       "      <td>0.99131</td>\n",
       "      <td>i love adore ed thank you the honor last night sir xo ace hotel downtown los angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nashville</th>\n",
       "      <td>227855</td>\n",
       "      <td>0.996379</td>\n",
       "      <td>at regions our mission is to make life better for our associates our communities and our customers come join our mission as our newest financial relationship consultant greater memphis tn area tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york</th>\n",
       "      <td>192478</td>\n",
       "      <td>0.998271</td>\n",
       "      <td>downtown brooklyn tonight \\r newyorkcity nyc brooklyn downtown brooklyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oklahoma city</th>\n",
       "      <td>30615</td>\n",
       "      <td>0.992344</td>\n",
       "      <td>see our latest wichita ks job and click to apply hr assistant wichita ks hr hiring careerarc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san francisco</th>\n",
       "      <td>64656</td>\n",
       "      <td>0.993493</td>\n",
       "      <td>want to work at waste management we're hiring in reno nv click for details hr job jobs careerarc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seattle</th>\n",
       "      <td>86234</td>\n",
       "      <td>0.999145</td>\n",
       "      <td>can you recommend anyone for this job senior engineer engineering engineer construction seattle wa hiring careerarc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tampa</th>\n",
       "      <td>356631</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>want to work at lane construction corporation we're hiring in orlando fl click for details job jobs careerarc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toronto</th>\n",
       "      <td>44712</td>\n",
       "      <td>0.997859</td>\n",
       "      <td>alarm highrise residential toronto \\r queen street\\r b w fee pl river street\\r dispatched 08 11 18 18 29 est\\r stn 325 aerial 325 distchief 33 pumper pumper pumper general area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>washington</th>\n",
       "      <td>155717</td>\n",
       "      <td>0.997387</td>\n",
       "      <td>want to work in baltimore md view our latest opening art job jobs hiring</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                index      prob  \\\n",
       "albuquerque     72883  0.155828   \n",
       "charlotte      154751  0.997735   \n",
       "chicago        337882   0.99812   \n",
       "cincinnati     252895  0.997226   \n",
       "houston        159792  0.994945   \n",
       "los angeles    204404   0.99131   \n",
       "nashville      227855  0.996379   \n",
       "new york       192478  0.998271   \n",
       "oklahoma city   30615  0.992344   \n",
       "san francisco   64656  0.993493   \n",
       "seattle         86234  0.999145   \n",
       "tampa          356631  0.997835   \n",
       "toronto         44712  0.997859   \n",
       "washington     155717  0.997387   \n",
       "\n",
       "                                                                                                                                                                                                                 tweet  \n",
       "albuquerque    ulta beauty is hiring our newest professional in carsoncity nv we would love to connect with you if interested click here to learn more beauty advisor seasonal hiring ultabeauty cosmetology job jo...  \n",
       "charlotte                                                                       your talent drives your legacy at construction apply today conway sc hiring construction construction charleston sc job jobs careerarc  \n",
       "chicago                                                                                               can you recommend anyone for this job software support engineer engineering chicago il veterans hiring careerarc  \n",
       "cincinnati     connect with us to help change the world if you’re ready to make an impact we’d love to hear from you please submit your for our newest open role in cincinnati oh site controller cincinnati oh fin...  \n",
       "houston                                                                                      want to work at performance food group we're hiring in shreveport la click for details driver cdl transportation job jobs  \n",
       "los angeles                                                                                                                       i love adore ed thank you the honor last night sir xo ace hotel downtown los angeles  \n",
       "nashville      at regions our mission is to make life better for our associates our communities and our customers come join our mission as our newest financial relationship consultant greater memphis tn area tod...  \n",
       "new york                                                                                                                                       downtown brooklyn tonight \\r newyorkcity nyc brooklyn downtown brooklyn  \n",
       "oklahoma city                                                                                                             see our latest wichita ks job and click to apply hr assistant wichita ks hr hiring careerarc  \n",
       "san francisco                                                                                                         want to work at waste management we're hiring in reno nv click for details hr job jobs careerarc  \n",
       "seattle                                                                                            can you recommend anyone for this job senior engineer engineering engineer construction seattle wa hiring careerarc  \n",
       "tampa                                                                                                    want to work at lane construction corporation we're hiring in orlando fl click for details job jobs careerarc  \n",
       "toronto                               alarm highrise residential toronto \\r queen street\\r b w fee pl river street\\r dispatched 08 11 18 18 29 est\\r stn 325 aerial 325 distchief 33 pumper pumper pumper general area  \n",
       "washington                                                                                                                                    want to work in baltimore md view our latest opening art job jobs hiring  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 200\n",
    "df_toptweets = pd.DataFrame.from_dict(best_tweets).T\n",
    "df_toptweets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

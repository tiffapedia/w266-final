{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tiffanyjaya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/tiffanyjaya/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our libraries \n",
    "import tweets_processor\n",
    "\n",
    "# general libraries \n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# model selection \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# model definition \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# model metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_model(features, target):  \n",
    "  \"\"\"A bag-of-words model. Note it disregards the word order in the text.\"\"\"  \n",
    "  target = tf.one_hot(target, 15, 1, 0)  \n",
    "  features = tf.contrib.layers.bow_encoder(      \n",
    "      features, vocab_size=n_words, embed_dim=EMBEDDING_SIZE)  \n",
    "  logits = tf.contrib.layers.fully_connected(features, 15,\n",
    "      activation_fn=None)  \n",
    "  loss = tf.contrib.losses.softmax_cross_entropy(logits, target)\n",
    "  train_op = tf.contrib.layers.optimize_loss(\n",
    "      loss, tf.contrib.framework.get_global_step(),      \n",
    "      optimizer='Adam', learning_rate=0.01)  \n",
    "  return (      \n",
    "      {'class': tf.argmax(logits, 1), \n",
    "       'prob': tf.nn.softmax(logits)},      \n",
    "      loss, train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = learn.Estimator(model_fn=bag_of_words_model) \n",
    "# Train and predict \n",
    "classifier.fit(x_train, y_train, steps=10000) \n",
    "y_predicted = [ p[â€˜classâ€™] for p in \n",
    "  classifier.predict(x_test, as_iterable=True)] \n",
    "score = metrics.accuracy_score(y_test, y_predicted) \n",
    "print(â€˜Accuracy: {0:f}â€™.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_text, tweets_place = tweets_processor.get_tweets_from_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a53310f3a396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0memoji\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test the ðŸ¤” ðŸ™ˆ emojis, in ðŸ˜Œ here ðŸ’•ðŸ‘­'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memoji\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNICODE_EMOJI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "s = 'test the ðŸ¤” ðŸ™ˆ emojis, in ðŸ˜Œ here ðŸ’•ðŸ‘­'\n",
    "s = ''.join(c for c in s if c not in emoji.UNICODE_EMOJI)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40001, 233794)\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = TfidfVectorizer(preprocessor = preprocessor, tokenizer=tokenizer)\n",
    "# using bigrams\n",
    "vectorizer = TfidfVectorizer(preprocessor = tweets_processor.preprocessor, tokenizer=tweets_processor.tokenizer,ngram_range=(2,2))\n",
    "tweets_vectorized = vectorizer.fit_transform(tweets_text)\n",
    "\n",
    "# length of total vocabulary\n",
    "#print(len(vectorizer.vocabulary_))\n",
    "print(tweets_vectorized.shape)\n",
    "\n",
    "\n",
    "# count vectorizer\n",
    "#count_vectorizer = CountVectorizer(preprocessor = preprocessor, tokenizer=tokenizer)\n",
    "#using bigrams\n",
    "count_vectorizer = CountVectorizer(preprocessor = tweets_processor.preprocessor, tokenizer=tweets_processor.tokenizer,ngram_range=(2,2))\n",
    "tweets_count_vectorized = count_vectorizer.fit_transform(tweets_text)\n",
    "\n",
    "# length of total vocabulary\n",
    "#print(count_vectorizer.vocabulary_)\n",
    "#print(count_vectorizer.get_feature_names())\n",
    "#print(tweets_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does anyone live in the Charleston area and want a job ($10/hr) for Nov 14-21? hmu   (0, 8844)\t0.36171867892689485\n",
      "  (0, 116112)\t0.36171867892689485\n",
      "  (0, 32675)\t0.36171867892689485\n",
      "  (0, 10298)\t0.3482676037537245\n",
      "  (0, 220606)\t0.338723914037543\n",
      "  (0, 102877)\t0.3313212531843311\n",
      "  (0, 95934)\t0.36171867892689485\n",
      "  (0, 140311)\t0.36171867892689485 cause much actually radical adventure alaska 3\n"
     ]
    }
   ],
   "source": [
    "# splitting the data into train, dev, test\n",
    "#train_data, train_labels = tweets_text[:700], tweets_place[:700] # ????see if we automatically split it proportinately irrespective of size \n",
    "#dev_data, dev_labels = tweets_text[700:901], tweets_place[700:901]\n",
    "#test_data, test_labels = tweets_text[901:], tweets_place[901:]\n",
    "print(tweets_text[1], tweets_vectorized[1], vectorizer.get_feature_names()[31054], vectorizer.get_feature_names()[1452], vectorizer.get_feature_names()[2172], tweets_place[1])\n",
    "\n",
    "# using train_test_split\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(tweets_vectorized, tweets_place, test_size=0.33, random_state=0)\n",
    "\n",
    "#using count vectorized tweets\n",
    "#train_data, test_data, train_labels, test_labels = train_test_split(tweets_count_vectorized, tweets_place, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x233794 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiffanyjaya/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 26.95%\n",
      "Accuracy on test set: 27.26%\n"
     ]
    }
   ],
   "source": [
    "# training the model using logisticRegression with multinomial\n",
    "####???? if there is a better library to use and a better classifier to use, should i svm, ridge classifier?\n",
    "\n",
    "# Logistic Regression\n",
    "lg = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "lg.fit(train_data, train_labels)\n",
    "\n",
    "print(\"Accuracy on test set: {:.02%}\".format(lg.score(test_data, test_labels)))\n",
    "# print(lg.score(test_data, test_labels))\n",
    "\n",
    "#Ridge Classifier\n",
    "rc = RidgeClassifier()\n",
    "rc.fit(train_data, train_labels)\n",
    "\n",
    "pred = rc.predict(test_data)\n",
    "\n",
    "print(\"Accuracy on test set: {:.02%}\".format(rc.score(test_data, test_labels)))\n",
    "#print(rc.score(test_data, test_labels))\n",
    "#print(classification_report(test_labels, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 26.83%\n"
     ]
    }
   ],
   "source": [
    "# using naive bayes\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_data, train_labels)\n",
    "y_pred = nb.predict(test_data)\n",
    "acc = accuracy_score(test_labels, y_pred)\n",
    "print(\"Accuracy on test set: {:.02%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using MLP classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, ),)\n",
    "mlp.fit(train_data, train_labels)\n",
    "y_pred = mlp.predict(test_data)\n",
    "acc = accuracy_score(test_labels, y_pred)\n",
    "print(\"Accuracy on test set: {:.02%}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Logic for the baseline model to get words for each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tweets_text[0], tweets_vectorized[1], vectorizer.get_feature_names()[1485], vectorizer.get_feature_names()[1452], vectorizer.get_feature_names()[2172], tweets_place[0])\n",
    "vocab = vectorizer.get_feature_names()\n",
    "place_word_score = defaultdict(lambda: defaultdict(lambda: 0.0))\n",
    "word_place_score = defaultdict(lambda: defaultdict(lambda: 0.0))\n",
    "word_score = dict()\n",
    "for index, tweet in enumerate(tweets_vectorized):\n",
    "    place = tweets_place[index]\n",
    "    for word_index, score in zip(tweet.indices, tweet.data):\n",
    "        word = vocab[word_index]\n",
    "        existing_place = place_word_score.get(place, None)\n",
    "        if existing_place is not None and existing_place.get(word, None) is not None:\n",
    "            score = existing_place.get(word) + score\n",
    "        # stores for each place what are all the words\n",
    "        place_word_score[place][word] = score\n",
    "        word_score_in_dict = word_score.get(word, None)\n",
    "        # update the dict with the place and word only when there is no word in dict(word_score) with a score or if the score is greater for this place than the previous place\n",
    "        # also update the word_score with new score\n",
    "        if word_score_in_dict is None or word_score_in_dict < score:\n",
    "            word_place_score[word] = {place:score}\n",
    "            word_score[word] = score\n",
    "print(word_place_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

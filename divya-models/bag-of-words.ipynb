{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import emoji\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import tweets_processor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# igonre this, this was the first file without regions\n",
    "# parsing json file containing tweets\n",
    "with open('tweets.json') as f_tweets:\n",
    "    json_tweets = json.load(f_tweets)\n",
    "#print(json_tweets[1]['text'])\n",
    "\n",
    "tweets_text = [] # should we change this to numpy\n",
    "tweets_place = []\n",
    "for tweet in json_tweets:\n",
    "    if (tweet['user']['geo_enabled'] == True):\n",
    "        tweets_text.append(tweet['text'])\n",
    "        tweets_place.append(tweet['place']['full_name'])\n",
    "\n",
    "#print(tweets_text[1])\n",
    "#print(len(tweets_text))\n",
    "#print(len(tweets_place))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_text, tweets_place = tweets_processor.get_tweets_from_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test the   emojis, in  here \n"
     ]
    }
   ],
   "source": [
    "s = 'test the ðŸ¤” ðŸ™ˆ emojis, in ðŸ˜Œ here ðŸ’•ðŸ‘­'\n",
    "s = ''.join(c for c in s if c not in emoji.UNICODE_EMOJI)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 64881)\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = TfidfVectorizer(preprocessor = preprocessor, tokenizer=tokenizer)\n",
    "# using bigrams\n",
    "vectorizer = TfidfVectorizer(preprocessor = tweets_processor.preprocessor, tokenizer=tweets_processor.tokenizer,ngram_range=(2,2))\n",
    "tweets_vectorized = vectorizer.fit_transform(tweets_text)\n",
    "\n",
    "# length of total vocabulary\n",
    "#print(len(vectorizer.vocabulary_))\n",
    "print(tweets_vectorized.shape)\n",
    "\n",
    "\n",
    "# count vectorizer\n",
    "#count_vectorizer = CountVectorizer(preprocessor = preprocessor, tokenizer=tokenizer)\n",
    "#using bigrams\n",
    "count_vectorizer = CountVectorizer(preprocessor = tweets_processor.preprocessor, tokenizer=tweets_processor.tokenizer,ngram_range=(2,2))\n",
    "tweets_count_vectorized = count_vectorizer.fit_transform(tweets_text)\n",
    "\n",
    "# length of total vocabulary\n",
    "#print(count_vectorizer.vocabulary_)\n",
    "#print(count_vectorizer.get_feature_names())\n",
    "#print(tweets_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When you like something on twit a lil pumpkin pops upðŸŽƒðŸ™ˆ   (0, 31054)\t0.4548641685301028\n",
      "  (0, 49677)\t0.4548641685301028\n",
      "  (0, 57029)\t0.4548641685301028\n",
      "  (0, 31209)\t0.4354858003208915\n",
      "  (0, 42986)\t0.4354858003208915 america phonies amendment requires another cap cincinnati\n"
     ]
    }
   ],
   "source": [
    "# splitting the data into train, dev, test\n",
    "#train_data, train_labels = tweets_text[:700], tweets_place[:700] # ????see if we automatically split it proportinately irrespective of size \n",
    "#dev_data, dev_labels = tweets_text[700:901], tweets_place[700:901]\n",
    "#test_data, test_labels = tweets_text[901:], tweets_place[901:]\n",
    "print(tweets_text[1], tweets_vectorized[1], vectorizer.get_feature_names()[31054], vectorizer.get_feature_names()[1452], vectorizer.get_feature_names()[2172], tweets_place[1])\n",
    "\n",
    "# using train_test_split\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(tweets_vectorized, tweets_place, test_size=0.33, random_state=0)\n",
    "\n",
    "#using count vectorized tweets\n",
    "#train_data, test_data, train_labels, test_labels = train_test_split(tweets_count_vectorized, tweets_place, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x62407 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 15.21%\n",
      "Accuracy on test set: 14.66%\n"
     ]
    }
   ],
   "source": [
    "# training the model using logisticRegression with multinomial\n",
    "####???? if there is a better library to use and a better classifier to use, should i svm, ridge classifier?\n",
    "\n",
    "# Logistic Regression\n",
    "lg = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "lg.fit(train_data, train_labels)\n",
    "\n",
    "print(\"Accuracy on test set: {:.02%}\".format(lg.score(test_data, test_labels)))\n",
    "# print(lg.score(test_data, test_labels))\n",
    "\n",
    "#Ridge Classifier\n",
    "rc = RidgeClassifier()\n",
    "rc.fit(train_data, train_labels)\n",
    "\n",
    "pred = rc.predict(test_data)\n",
    "\n",
    "print(\"Accuracy on test set: {:.02%}\".format(rc.score(test_data, test_labels)))\n",
    "#print(rc.score(test_data, test_labels))\n",
    "#print(classification_report(test_labels, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 13.90%\n"
     ]
    }
   ],
   "source": [
    "# using naive bayes\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_data, train_labels)\n",
    "y_pred = nb.predict(test_data)\n",
    "acc = accuracy_score(test_labels, y_pred)\n",
    "print(\"Accuracy on test set: {:.02%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 13.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divyagorantla/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "# using MLP classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, ),)\n",
    "mlp.fit(train_data, train_labels)\n",
    "y_pred = mlp.predict(test_data)\n",
    "acc = accuracy_score(test_labels, y_pred)\n",
    "print(\"Accuracy on test set: {:.02%}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Logic for the baseline model to get words for each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tweets_text[0], tweets_vectorized[1], vectorizer.get_feature_names()[1485], vectorizer.get_feature_names()[1452], vectorizer.get_feature_names()[2172], tweets_place[0])\n",
    "vocab = vectorizer.get_feature_names()\n",
    "place_word_score = defaultdict(lambda: defaultdict(lambda: 0.0))\n",
    "word_place_score = defaultdict(lambda: defaultdict(lambda: 0.0))\n",
    "word_score = dict()\n",
    "for index, tweet in enumerate(tweets_vectorized):\n",
    "    place = tweets_place[index]\n",
    "    for word_index, score in zip(tweet.indices, tweet.data):\n",
    "        word = vocab[word_index]\n",
    "        existing_place = place_word_score.get(place, None)\n",
    "        if existing_place is not None and existing_place.get(word, None) is not None:\n",
    "            score = existing_place.get(word) + score\n",
    "        # stores for each place what are all the words\n",
    "        place_word_score[place][word] = score\n",
    "        word_score_in_dict = word_score.get(word, None)\n",
    "        # update the dict with the place and word only when there is no word in dict(word_score) with a score or if the score is greater for this place than the previous place\n",
    "        # also update the word_score with new score\n",
    "        if word_score_in_dict is None or word_score_in_dict < score:\n",
    "            word_place_score[word] = {place:score}\n",
    "            word_score[word] = score\n",
    "print(word_place_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
